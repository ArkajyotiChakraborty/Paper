{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Glove+CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgDG9IiOrlX2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.layers import LSTM, Activation, Dropout, Dense, Input, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model\n",
        "import string\n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "3Ikso3zbtHhF",
        "outputId": "4e805d5c-8125-4068-9964-6db4320aed13"
      },
      "source": [
        "df = pd.read_csv('Processed_Data.csv', engine = 'python')\n",
        "df"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>topic</th>\n",
              "      <th>tweet</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>class</th>\n",
              "      <th>processed_tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>#olympics</td>\n",
              "      <td>Aussies would be happy that the T20 series hap...</td>\n",
              "      <td>0.275</td>\n",
              "      <td>Positive</td>\n",
              "      <td>aussie would happy series happen midst olympic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>#olympics</td>\n",
              "      <td>The worst thing about the #Olympics finishing ...</td>\n",
              "      <td>-0.13333333333333333</td>\n",
              "      <td>Negative</td>\n",
              "      <td>worst thing olympics finish whole week availab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>#olympics</td>\n",
              "      <td>#Olympics\\n\\nWe play for India: #Hockey captai...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>olympics play india hockey captain ranirampal ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>#olympics</td>\n",
              "      <td>See the best moments from the #Tokyo2020 closi...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>see best moment tokyo close ceremony videoelep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>#olympics</td>\n",
              "      <td>Fabulous! #Olympics \\n#LoveTheBBC \\n\\nTokyo Ol...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>Positive</td>\n",
              "      <td>fabulous olympics lovethebbc tokyo olympics bb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140253</th>\n",
              "      <td>140242</td>\n",
              "      <td>Tokyo olympics</td>\n",
              "      <td>Congratulations to all our winners and partici...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>Positive</td>\n",
              "      <td>congratulation winner participant olympics win...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140254</th>\n",
              "      <td>140243</td>\n",
              "      <td>Tokyo olympics</td>\n",
              "      <td>I hope that I am wrong but I have seen no twee...</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>Negative</td>\n",
              "      <td>hope wrong see tweet government</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140255</th>\n",
              "      <td>140244</td>\n",
              "      <td>Tokyo olympics</td>\n",
              "      <td>Tokyo passes the baton to Paris as strangest e...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>tokyo pass baton paris strangest ever olympic ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140256</th>\n",
              "      <td>140245</td>\n",
              "      <td>Tokyo olympics</td>\n",
              "      <td>Paris plans to deliver inclusive, youth-centre...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>paris plan deliver inclusive youth centre gend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140257</th>\n",
              "      <td>140246</td>\n",
              "      <td>Tokyo olympics</td>\n",
              "      <td>Tokyo Games could yet have positive legacy des...</td>\n",
              "      <td>0.41363636363636364</td>\n",
              "      <td>Positive</td>\n",
              "      <td>tokyo game could yet positive legacy despite u...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>140258 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...                                   processed_tweets\n",
              "0               0  ...  aussie would happy series happen midst olympic...\n",
              "1               1  ...  worst thing olympics finish whole week availab...\n",
              "2               2  ...  olympics play india hockey captain ranirampal ...\n",
              "3               3  ...  see best moment tokyo close ceremony videoelep...\n",
              "4               4  ...  fabulous olympics lovethebbc tokyo olympics bb...\n",
              "...           ...  ...                                                ...\n",
              "140253     140242  ...  congratulation winner participant olympics win...\n",
              "140254     140243  ...                    hope wrong see tweet government\n",
              "140255     140244  ...  tokyo pass baton paris strangest ever olympic ...\n",
              "140256     140245  ...  paris plan deliver inclusive youth centre gend...\n",
              "140257     140246  ...  tokyo game could yet positive legacy despite u...\n",
              "\n",
              "[140258 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZz55UwItaeB"
      },
      "source": [
        "Downloading the Pre-trained GLove File's"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8PektJitYif",
        "outputId": "fcdc51e9-f14c-43ed-889c-125cae748e19"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-01 07:16:18--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-10-01 07:16:18--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-10-01 07:16:19--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: â€˜glove.6B.zipâ€™\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.24MB/s    in 2m 42s  \n",
            "\n",
            "2021-10-01 07:19:01 (5.09 MB/s) - â€˜glove.6B.zipâ€™ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AEPHFUXt1fH",
        "outputId": "a5d4e85f-9934-407a-b0c8-066b702bb110"
      },
      "source": [
        "df = df.dropna()\n",
        "df.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(139707, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIxQYwJnuxTO"
      },
      "source": [
        "def ratio(x):\n",
        "  if x=='Positive':\n",
        "    return 1\n",
        "  elif x=='Negative':\n",
        "    return 2\n",
        "  else:\n",
        "    return 0;"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "29NqM7Oyu2jt",
        "outputId": "ff9c59ad-8dee-4ea3-cc7d-0a2f4637141e"
      },
      "source": [
        "df['label'] = df['class'].apply(ratio)\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>topic</th>\n",
              "      <th>tweet</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>class</th>\n",
              "      <th>processed_tweets</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>#olympics</td>\n",
              "      <td>Aussies would be happy that the T20 series hap...</td>\n",
              "      <td>0.275</td>\n",
              "      <td>Positive</td>\n",
              "      <td>aussie would happy series happen midst olympic...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>#olympics</td>\n",
              "      <td>The worst thing about the #Olympics finishing ...</td>\n",
              "      <td>-0.13333333333333333</td>\n",
              "      <td>Negative</td>\n",
              "      <td>worst thing olympics finish whole week availab...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>#olympics</td>\n",
              "      <td>#Olympics\\n\\nWe play for India: #Hockey captai...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>olympics play india hockey captain ranirampal ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>#olympics</td>\n",
              "      <td>See the best moments from the #Tokyo2020 closi...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>see best moment tokyo close ceremony videoelep...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>#olympics</td>\n",
              "      <td>Fabulous! #Olympics \\n#LoveTheBBC \\n\\nTokyo Ol...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>Positive</td>\n",
              "      <td>fabulous olympics lovethebbc tokyo olympics bb...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Unnamed: 0  ... label\n",
              "0          0  ...     1\n",
              "1          1  ...     2\n",
              "2          2  ...     0\n",
              "3          3  ...     1\n",
              "4          4  ...     1\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8xwPzJxu9az",
        "outputId": "af35bad6-fb27-4aa8-cb44-28fc0b75daab"
      },
      "source": [
        "df.processed_tweets = df.processed_tweets.astype(str)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:5170: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[name] = value\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_r47Sf9u-Z0"
      },
      "source": [
        "y = df['label']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAGSzfeLv-BV"
      },
      "source": [
        "x = df['processed_tweets']"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAcorX8yvLmH",
        "outputId": "eaa1e2d0-93a3-4d6e-c346-8ea7b5ca383e"
      },
      "source": [
        "reviews = df['processed_tweets']\n",
        "reviews"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         aussie would happy series happen midst olympic...\n",
              "1         worst thing olympics finish whole week availab...\n",
              "2         olympics play india hockey captain ranirampal ...\n",
              "3         see best moment tokyo close ceremony videoelep...\n",
              "4         fabulous olympics lovethebbc tokyo olympics bb...\n",
              "                                ...                        \n",
              "140253    congratulation winner participant olympics win...\n",
              "140254                      hope wrong see tweet government\n",
              "140255    tokyo pass baton paris strangest ever olympic ...\n",
              "140256    paris plan deliver inclusive youth centre gend...\n",
              "140257    tokyo game could yet positive legacy despite u...\n",
              "Name: processed_tweets, Length: 139707, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oht7a_0lvRmN"
      },
      "source": [
        "X_train, X_test,Y_train, Y_test = train_test_split(x, y, test_size=0.2, random_state = 45)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQr6NIGbwH1M",
        "outputId": "9cd7666c-8be2-430a-9169-2745ef356a6a"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(111765,)\n",
            "(27942,)\n",
            "(111765,)\n",
            "(27942,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THITqyDHwYHV",
        "outputId": "5aef51c7-6471-4a46-d589-07b22f322e0e"
      },
      "source": [
        "len(Y_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "111765"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7NaCIJywdSX"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mU7N2NCw5Sk",
        "outputId": "137281e3-0aed-4aa6-e9ec-99fbecf41d0c"
      },
      "source": [
        "words_to_index = tokenizer.word_index\n",
        "len(words_to_index)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37826"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiHS-FFPw8rE"
      },
      "source": [
        "def read_glove_vector(glove_vec):\n",
        "  with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
        "    words = set()\n",
        "    word_to_vec_map = {}\n",
        "    for line in f:\n",
        "      w_line = line.split()\n",
        "      curr_word = w_line[0]\n",
        "      word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
        "\n",
        "\n",
        "\n",
        "  return word_to_vec_map"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dGj7r5ww_As"
      },
      "source": [
        "word_to_vec_map = read_glove_vector('glove.6B.50d.txt')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSixtW99xDrM"
      },
      "source": [
        "maxLen = 150\n",
        "vocab_len = len(words_to_index)\n",
        "embed_vector_len = word_to_vec_map['moon'].shape[0]\n",
        "\n",
        "emb_matrix = np.zeros((vocab_len, embed_vector_len))\n",
        "\n",
        "for word, index in words_to_index.items():\n",
        "  embedding_vector = word_to_vec_map.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    emb_matrix[index-1, :] = embedding_vector\n",
        "\n",
        "embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=maxLen, weights = [emb_matrix], trainable=False)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csWTvizAxKCN",
        "outputId": "383a4349-e2d2-4220-f091-e892a92c5468"
      },
      "source": [
        "embedding_layer"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f399b629690>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEYTFFwTxMUW"
      },
      "source": [
        "def conv1d_model(input_shape):\n",
        "\n",
        "  X_indices = Input(input_shape)\n",
        "\n",
        "  embeddings = embedding_layer(X_indices)\n",
        "\n",
        "  X = Conv1D(512,3,activation='relu')(embeddings)\n",
        "  \n",
        "  X = MaxPooling1D(3)(X)\n",
        "\n",
        "  X = Conv1D(256,3,activation='relu')(X)\n",
        "  \n",
        "  X = MaxPooling1D(3)(X)\n",
        "\n",
        "  X = Conv1D(256,3,activation='relu')(X)\n",
        "  X = Dropout(0.8)(X)\n",
        "  X = MaxPooling1D(3)(X)\n",
        "\n",
        "  X = GlobalMaxPooling1D()(X)\n",
        "\n",
        "  X = Dense(256, activation='relu')(X)\n",
        "  X = Dense(3, activation='softmax')(X)\n",
        "\n",
        "  model = Model(inputs=X_indices, outputs=X)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmYYVhsUxX2U",
        "outputId": "8ba4687a-9b1b-4e16-d049-60d40367eb4d"
      },
      "source": [
        "model_1d = conv1d_model((maxLen,))\n",
        "model_1d.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 150)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 150, 50)           1891300   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 148, 512)          77312     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 49, 512)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 47, 256)           393472    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 15, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 13, 256)           196864    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 13, 256)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 4, 256)            0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 2,625,511\n",
            "Trainable params: 734,211\n",
            "Non-trainable params: 1,891,300\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kylnQmjNxZO3"
      },
      "source": [
        "X_train_indices = tokenizer.texts_to_sequences(X_train)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsO1CNplxhHe",
        "outputId": "673f7328-ab3a-40ea-e4ad-ed75c4819996"
      },
      "source": [
        "X_train_indices = pad_sequences(X_train_indices, maxlen=maxLen, padding='post')\n",
        "X_train_indices.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(111765, 150)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2mliGncx_C2"
      },
      "source": [
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHoqV3rdxqyn"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgdBJ4Q-ywvC"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxRvlSAhyUJv"
      },
      "source": [
        "recall = tf.keras.metrics.Recall()\n",
        "precision = tf.keras.metrics.Precision()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyxpdt8Rxjo9"
      },
      "source": [
        "\n",
        "model_1d.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AFiUCc0xzvQ",
        "outputId": "0b2968d3-bff6-4c05-8420-5f596dc2bc50"
      },
      "source": [
        "model_1d.fit(X_train_indices, Y_train, batch_size=64, epochs=10)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1747/1747 [==============================] - 398s 227ms/step - loss: 0.8356 - accuracy: 0.6164\n",
            "Epoch 2/10\n",
            "1747/1747 [==============================] - 400s 229ms/step - loss: 0.6708 - accuracy: 0.7205\n",
            "Epoch 3/10\n",
            "1747/1747 [==============================] - 398s 228ms/step - loss: 0.5740 - accuracy: 0.7713\n",
            "Epoch 4/10\n",
            "1747/1747 [==============================] - 397s 227ms/step - loss: 0.5032 - accuracy: 0.8045\n",
            "Epoch 5/10\n",
            "1747/1747 [==============================] - 399s 228ms/step - loss: 0.4493 - accuracy: 0.8282\n",
            "Epoch 6/10\n",
            "1747/1747 [==============================] - 399s 229ms/step - loss: 0.3968 - accuracy: 0.8529\n",
            "Epoch 7/10\n",
            "1747/1747 [==============================] - 396s 227ms/step - loss: 0.3545 - accuracy: 0.8705\n",
            "Epoch 8/10\n",
            "1747/1747 [==============================] - 396s 227ms/step - loss: 0.3144 - accuracy: 0.8871\n",
            "Epoch 9/10\n",
            "1747/1747 [==============================] - 398s 228ms/step - loss: 0.2810 - accuracy: 0.9008\n",
            "Epoch 10/10\n",
            "1747/1747 [==============================] - 399s 229ms/step - loss: 0.2539 - accuracy: 0.9111\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3995e79b10>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pgt_cmphDtoQ"
      },
      "source": [
        "X_test_indices = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_indices = pad_sequences(X_test_indices, maxlen=maxLen, padding='post')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf9As8ibDxiP",
        "outputId": "26665da9-50cc-4afe-e97a-9b74132adf4e"
      },
      "source": [
        "model_1d.evaluate(X_test_indices, Y_test)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "874/874 [==============================] - 28s 32ms/step - loss: 0.5487 - accuracy: 0.7955\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5487364530563354, 0.7955407500267029]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    }
  ]
}