{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GLOVE+LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtXyyDz8EBYW"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn import preprocessing\n",
        "from tqdm import tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.layers.recurrent import LSTM, GRU\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "UkwX83fyFAJB",
        "outputId": "e18b30a1-71a1-45d4-8171-8e2fc3512426"
      },
      "source": [
        "df = pd.read_csv('Processed_Data.csv', engine = 'python')\n",
        "df"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>topic</th>\n",
              "      <th>tweet</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>class</th>\n",
              "      <th>processed_tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>#olympics</td>\n",
              "      <td>Aussies would be happy that the T20 series hap...</td>\n",
              "      <td>0.275</td>\n",
              "      <td>Positive</td>\n",
              "      <td>aussie would happy series happen midst olympic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>#olympics</td>\n",
              "      <td>The worst thing about the #Olympics finishing ...</td>\n",
              "      <td>-0.13333333333333333</td>\n",
              "      <td>Negative</td>\n",
              "      <td>worst thing olympics finish whole week availab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>#olympics</td>\n",
              "      <td>#Olympics\\n\\nWe play for India: #Hockey captai...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>olympics play india hockey captain ranirampal ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>#olympics</td>\n",
              "      <td>See the best moments from the #Tokyo2020 closi...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>see best moment tokyo close ceremony videoelep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>#olympics</td>\n",
              "      <td>Fabulous! #Olympics \\n#LoveTheBBC \\n\\nTokyo Ol...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>Positive</td>\n",
              "      <td>fabulous olympics lovethebbc tokyo olympics bb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140253</th>\n",
              "      <td>140242</td>\n",
              "      <td>Tokyo olympics</td>\n",
              "      <td>Congratulations to all our winners and partici...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>Positive</td>\n",
              "      <td>congratulation winner participant olympics win...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140254</th>\n",
              "      <td>140243</td>\n",
              "      <td>Tokyo olympics</td>\n",
              "      <td>I hope that I am wrong but I have seen no twee...</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>Negative</td>\n",
              "      <td>hope wrong see tweet government</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140255</th>\n",
              "      <td>140244</td>\n",
              "      <td>Tokyo olympics</td>\n",
              "      <td>Tokyo passes the baton to Paris as strangest e...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>tokyo pass baton paris strangest ever olympic ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140256</th>\n",
              "      <td>140245</td>\n",
              "      <td>Tokyo olympics</td>\n",
              "      <td>Paris plans to deliver inclusive, youth-centre...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>paris plan deliver inclusive youth centre gend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140257</th>\n",
              "      <td>140246</td>\n",
              "      <td>Tokyo olympics</td>\n",
              "      <td>Tokyo Games could yet have positive legacy des...</td>\n",
              "      <td>0.41363636363636364</td>\n",
              "      <td>Positive</td>\n",
              "      <td>tokyo game could yet positive legacy despite u...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>140258 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...                                   processed_tweets\n",
              "0               0  ...  aussie would happy series happen midst olympic...\n",
              "1               1  ...  worst thing olympics finish whole week availab...\n",
              "2               2  ...  olympics play india hockey captain ranirampal ...\n",
              "3               3  ...  see best moment tokyo close ceremony videoelep...\n",
              "4               4  ...  fabulous olympics lovethebbc tokyo olympics bb...\n",
              "...           ...  ...                                                ...\n",
              "140253     140242  ...  congratulation winner participant olympics win...\n",
              "140254     140243  ...                    hope wrong see tweet government\n",
              "140255     140244  ...  tokyo pass baton paris strangest ever olympic ...\n",
              "140256     140245  ...  paris plan deliver inclusive youth centre gend...\n",
              "140257     140246  ...  tokyo game could yet positive legacy despite u...\n",
              "\n",
              "[140258 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmD5wRsBGLVh",
        "outputId": "b284426d-d13b-4169-8d1f-858445906b43"
      },
      "source": [
        "df = df.dropna()\n",
        "df.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(139707, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STtXuRFKpIps",
        "outputId": "c1097a6d-cf50-498b-85c4-852e12bdda9f"
      },
      "source": [
        "label_encoder = preprocessing.LabelEncoder()\n",
        "labels = label_encoder.fit_transform(df['class'].values)\n",
        "np.unique(labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZHAzARBpaKn"
      },
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(df.processed_tweets.values, labels, \n",
        " random_state=42, \n",
        " test_size=0.2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaUdqtdNppXK",
        "outputId": "c0d91eaf-7c94-4a17-c0d1-491933da067a"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-01 11:39:22--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-10-01 11:39:22--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-10-01 11:39:23--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.18MB/s    in 2m 40s  \n",
            "\n",
            "2021-10-01 11:42:03 (5.14 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN7EmYFUqb1e",
        "outputId": "b5423dcb-5603-46fa-d369-469709d4f51b"
      },
      "source": [
        "embeddings_index = {}\n",
        "f = open('/content/glove.6B.100d.txt',encoding='utf8')\n",
        "for line in tqdm(f):\n",
        " values = line.split()\n",
        " word = values[0]\n",
        " coefs = np.asarray(values[1:], dtype='float32')\n",
        " embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "400000it [00:11, 33392.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX8f0-hxq4eY"
      },
      "source": [
        "VOCABULARY_SIZE = 2000\n",
        "MAX_LENGTH = 60"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv9wlqQEq7df"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=VOCABULARY_SIZE)\n",
        "tokenizer.fit_on_texts(list(xtrain) + list(xtest))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVqh_OSeq-7i"
      },
      "source": [
        "xtrain_sequence = tokenizer.texts_to_sequences(xtrain)\n",
        "xtest_sequence = tokenizer.texts_to_sequences(xtest)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44_Q_dR6rC8S"
      },
      "source": [
        "xtrain_padding = sequence.pad_sequences(xtrain_sequence, maxlen=MAX_LENGTH)\n",
        "xtest_padding = sequence.pad_sequences(xtest_sequence, maxlen=MAX_LENGTH)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzfS-J_4rfq-",
        "outputId": "b0859980-ec7b-43ac-b198-faf99e42d1e7"
      },
      "source": [
        "embedding_matrix = np.zeros((len(word_index) + 1,100))\n",
        "for word, i in tqdm(word_index.items()):\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 42086/42086 [00:00<00:00, 264676.08it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkOSvYxXsW4R"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1,\n",
        " 100,\n",
        " weights=[embedding_matrix],\n",
        " input_length=MAX_LENGTH,\n",
        " trainable=False))\n",
        "model.add(SpatialDropout1D(0.3))\n",
        "model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i00rz8Hbs4OT",
        "outputId": "859fa471-99a6-43f6-dc7f-0e1647f84c5f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 60, 100)           4208700   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 60, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              103424    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 3075      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 5,445,199\n",
            "Trainable params: 1,236,499\n",
            "Non-trainable params: 4,208,700\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35zebL0Rs8mr"
      },
      "source": [
        "ytrain_encode = np_utils.to_categorical(ytrain)\n",
        "ytest_encode = np_utils.to_categorical(ytest)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDWeKJkLs_e7",
        "outputId": "c3ad9f05-ebf6-459e-fd17-634dd1de5951"
      },
      "source": [
        "history = model.fit(xtrain_padding, y=ytrain_encode, batch_size=512, epochs=10, verbose=1, validation_data=(xtest_padding, ytest_encode))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "219/219 [==============================] - 217s 991ms/step - loss: 0.5006 - accuracy: 0.8071 - val_loss: 0.4233 - val_accuracy: 0.8508\n",
            "Epoch 2/10\n",
            "219/219 [==============================] - 217s 990ms/step - loss: 0.4937 - accuracy: 0.8118 - val_loss: 0.4178 - val_accuracy: 0.8531\n",
            "Epoch 3/10\n",
            "219/219 [==============================] - 218s 994ms/step - loss: 0.4908 - accuracy: 0.8127 - val_loss: 0.4144 - val_accuracy: 0.8527\n",
            "Epoch 4/10\n",
            "219/219 [==============================] - 217s 990ms/step - loss: 0.4873 - accuracy: 0.8144 - val_loss: 0.4140 - val_accuracy: 0.8549\n",
            "Epoch 5/10\n",
            "219/219 [==============================] - 217s 993ms/step - loss: 0.4854 - accuracy: 0.8156 - val_loss: 0.4183 - val_accuracy: 0.8536\n",
            "Epoch 6/10\n",
            "219/219 [==============================] - 217s 992ms/step - loss: 0.4819 - accuracy: 0.8172 - val_loss: 0.4078 - val_accuracy: 0.8570\n",
            "Epoch 7/10\n",
            "219/219 [==============================] - 217s 990ms/step - loss: 0.4785 - accuracy: 0.8177 - val_loss: 0.4069 - val_accuracy: 0.8594\n",
            "Epoch 8/10\n",
            "219/219 [==============================] - 217s 992ms/step - loss: 0.4771 - accuracy: 0.8195 - val_loss: 0.4101 - val_accuracy: 0.8583\n",
            "Epoch 9/10\n",
            "219/219 [==============================] - 217s 989ms/step - loss: 0.4768 - accuracy: 0.8200 - val_loss: 0.4106 - val_accuracy: 0.8603\n",
            "Epoch 10/10\n",
            "219/219 [==============================] - 217s 989ms/step - loss: 0.4724 - accuracy: 0.8212 - val_loss: 0.3981 - val_accuracy: 0.8619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z6x1liR1gyV",
        "outputId": "882ee44c-aefa-42b4-d715-0f8a15bb99e3"
      },
      "source": [
        "model.evaluate(xtest_padding, ytest_encode)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "874/874 [==============================] - 22s 25ms/step - loss: 0.3981 - accuracy: 0.8619\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3981074392795563, 0.8618566989898682]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llb84EkB1gvo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}